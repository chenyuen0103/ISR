{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0e03ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:23:50.843862Z",
     "start_time": "2023-09-17T20:23:24.768177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from configs.model_config import model_attributes\n",
    "from data import dataset_attributes, shift_types, prepare_data, log_data\n",
    "from utils.train_utils import set_seed, Logger, CSVBatchLogger, log_args\n",
    "from train import train\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c703bb5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:25:01.095041Z",
     "start_time": "2023-09-17T20:25:01.045594Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_args(args):\n",
    "    if args.shift_type == 'confounder':\n",
    "        assert args.confounder_names\n",
    "        assert args.target_name\n",
    "    elif args.shift_type.startswith('label_shift'):\n",
    "        assert args.minority_fraction\n",
    "        assert args.imbalance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ba70d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:37:50.985417Z",
     "start_time": "2023-09-17T20:37:50.901524Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Settings\n",
    "parser.add_argument('-d', '--dataset', choices=dataset_attributes.keys(), required=True)\n",
    "parser.add_argument('-s', '--shift_type', choices=shift_types, default='confounder')\n",
    "# Confounders\n",
    "parser.add_argument('-t', '--target_name')\n",
    "parser.add_argument('-c', '--confounder_names', nargs='+')\n",
    "# Resume?\n",
    "parser.add_argument('--resume', default=False, action='store_true')\n",
    "# Label shifts\n",
    "parser.add_argument('--minority_fraction', type=float)\n",
    "parser.add_argument('--imbalance_ratio', type=float)\n",
    "# Data\n",
    "parser.add_argument('--fraction', type=float, default=1.0)\n",
    "parser.add_argument('--root_dir', default=None)\n",
    "parser.add_argument('--reweight_groups', action='store_true', default=False)\n",
    "parser.add_argument('--augment_data', action='store_true', default=False)\n",
    "parser.add_argument('--val_fraction', type=float, default=0.1)\n",
    "# Objective\n",
    "parser.add_argument('--robust', default=False, action='store_true')\n",
    "parser.add_argument('--alpha', type=float, default=0.2)\n",
    "parser.add_argument('--generalization_adjustment', default=\"0.0\")\n",
    "parser.add_argument('--automatic_adjustment', default=False, action='store_true')\n",
    "parser.add_argument('--robust_step_size', default=0.01, type=float)\n",
    "parser.add_argument('--use_normalized_loss', default=False, action='store_true')\n",
    "parser.add_argument('--btl', default=False, action='store_true')\n",
    "parser.add_argument('--hinge', default=False, action='store_true')\n",
    "\n",
    "# Model\n",
    "parser.add_argument(\n",
    "    '--model',\n",
    "    choices=model_attributes.keys(),\n",
    "    default='resnet50')\n",
    "parser.add_argument('--train_from_scratch', action='store_true', default=False)\n",
    "\n",
    "# Optimization\n",
    "parser.add_argument('--n_epochs', type=int, default=4)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--lr', type=float, default=0.001)\n",
    "parser.add_argument('--scheduler', action='store_true', default=False)\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5)\n",
    "parser.add_argument('--gamma', type=float, default=0.1)\n",
    "parser.add_argument('--minimum_variational_weight', type=float, default=0)\n",
    "# Misc\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--show_progress', default=False, action='store_true')\n",
    "parser.add_argument('--log_dir', default='../inv-feature/logs/')\n",
    "parser.add_argument('--log_every', default=1e8, type=int)\n",
    "parser.add_argument('--save_step', type=int, default=1e8)\n",
    "parser.add_argument('--save_best', action='store_true', default=False)\n",
    "parser.add_argument('--save_last', action='store_true', default=False)\n",
    "\n",
    "multinli_command = ['-s', 'confounder', '-d', 'MultiNLI', '-t', 'gold_label_random',\n",
    "           '-c', 'sentence2_has_negation', '--batch_size', '32', '--model', 'bert',\n",
    "           '--n_epochs', '3', '--seed', '0']\n",
    "celeba_command = ['-d', 'CelebA', '-t', 'Blond_Hair', '-c', 'Male', '--model', 'resnet50',\n",
    "                  '--weight_decay', '0.01', '--lr', '0.0001',\n",
    "                   \"--batch_size\", '128', '--n_epochs', '50']\n",
    "waterbird_command = ['-d', 'CUB', '-t', 'waterbird_complete95', '-c', 'forest2water2', \n",
    "                     '--model', 'resnet50', '--weight_decay', '0.1', '--lr', '0.0001',\n",
    "                '--batch_size', '128', '--n_epochs', '300']\n",
    "command = multinli_command\n",
    "command += ['--seed', '0']\n",
    "args = parser.parse_args(args=command)\n",
    "check_args(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d482ce20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:34:54.898712Z",
     "start_time": "2023-09-17T20:34:54.762708Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_setDevice'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mset_device(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      2\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m preprocess \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/isr/lib/python3.11/site-packages/torch/cuda/__init__.py:350\u001B[0m, in \u001B[0;36mset_device\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    348\u001B[0m device \u001B[38;5;241m=\u001B[39m _get_device_index(device)\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 350\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_cuda_setDevice(device)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch._C' has no attribute '_cuda_setDevice'"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device('cuda')\n",
    "preprocess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac46692b-5dde-4afb-8b53-1d1c946d9d78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:36:00.506144Z",
     "start_time": "2023-09-17T20:35:15.930086Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:17<00:00, 20.2MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "model, preprocess = clip.load('ViT-B/32', 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dce5a0-9b07-43f0-8a02-ba826cc62ff7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import open_clip\n",
    "\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6735b0d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:39:29.665145Z",
     "start_time": "2023-09-17T20:38:04.579928Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.model == 'bert':\n",
    "    args.max_grad_norm = 1.0\n",
    "    args.adam_epsilon = 1e-8\n",
    "    args.warmup_steps = 0\n",
    "\n",
    "if args.robust:\n",
    "    algo = 'groupDRO'\n",
    "elif args.reweight_groups:\n",
    "    algo = 'reweight'\n",
    "else:\n",
    "    algo = 'ERM'\n",
    "\n",
    "args.log_dir = os.path.join(args.log_dir, args.dataset, algo, f's{args.seed}')\n",
    "\n",
    "if os.path.exists(args.log_dir) and args.resume:\n",
    "    resume=True\n",
    "    mode='a'\n",
    "else:\n",
    "    resume=False\n",
    "    mode='w'\n",
    "\n",
    "## Initialize logs\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "set_seed(args.seed)\n",
    "# Data\n",
    "# Test data for label_shift_step is not implemented yet\n",
    "test_data = None\n",
    "test_loader = None\n",
    "if args.shift_type == 'confounder':\n",
    "    train_data, val_data, test_data = prepare_data(args, train=True,train_transform=preprocess,eval_transform=preprocess)\n",
    "elif args.shift_type == 'label_shift_step':\n",
    "    train_data, val_data = prepare_data(args, train=True)\n",
    "\n",
    "loader_kwargs = {'batch_size':args.batch_size, 'num_workers':4, 'pin_memory':True}\n",
    "train_loader = train_data.get_loader(train=True, reweight_groups=args.reweight_groups, **loader_kwargs)\n",
    "val_loader = val_data.get_loader(train=False, reweight_groups=None, **loader_kwargs)\n",
    "if test_data is not None:\n",
    "    test_loader = test_data.get_loader(train=False, reweight_groups=None, **loader_kwargs)\n",
    "\n",
    "data = {}\n",
    "data['train_loader'] = train_loader\n",
    "data['val_loader'] = val_loader\n",
    "data['test_loader'] = test_loader\n",
    "data['train_data'] = train_data\n",
    "data['val_data'] = val_data\n",
    "data['test_data'] = test_data\n",
    "n_classes = train_data.n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T20:40:11.873620Z",
     "start_time": "2023-09-17T20:40:11.793084Z"
    }
   },
   "id": "bf0cf95c1b2d9ac4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7cdcada",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:44:42.186818Z",
     "start_time": "2023-09-17T20:43:03.425594Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:00<00:00, 733791.37B/s]\n",
      "100%|██████████| 440473133/440473133 [01:09<00:00, 6320360.83B/s] \n"
     ]
    }
   ],
   "source": [
    "## Initialize model\n",
    "pretrained = not args.train_from_scratch\n",
    "if resume:\n",
    "    model = torch.load(os.path.join(args.log_dir, 'last_model.pth'))\n",
    "    d = train_data.input_size()[0]\n",
    "elif model_attributes[args.model]['feature_type'] in ('precomputed', 'raw_flattened'):\n",
    "    assert pretrained\n",
    "    # Load precomputed features\n",
    "    d = train_data.input_size()[0]\n",
    "    model = nn.Linear(d, n_classes)\n",
    "    model.has_aux_logits = False\n",
    "elif args.model == 'resnet50':\n",
    "    model = torchvision.models.resnet50(pretrained=pretrained)\n",
    "    d = model.fc.in_features\n",
    "    model.fc = nn.Linear(d, n_classes)\n",
    "elif args.model == 'resnet34':\n",
    "    model = torchvision.models.resnet34(pretrained=pretrained)\n",
    "    d = model.fc.in_features\n",
    "    model.fc = nn.Linear(d, n_classes)\n",
    "elif args.model == 'wideresnet50':\n",
    "    model = torchvision.models.wide_resnet50_2(pretrained=pretrained)\n",
    "    d = model.fc.in_features\n",
    "    model.fc = nn.Linear(d, n_classes)\n",
    "elif args.model == 'bert':\n",
    "    assert args.dataset == 'MultiNLI'\n",
    "\n",
    "    from pytorch_transformers import BertConfig, BertForSequenceClassification\n",
    "    config_class = BertConfig\n",
    "    model_class = BertForSequenceClassification\n",
    "\n",
    "    config = config_class.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=3,\n",
    "        finetuning_task='mnli')\n",
    "    model = model_class.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        from_tf=False,\n",
    "        config=config)\n",
    "else:\n",
    "    raise ValueError('Model not recognized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c37cff-0035-4b9d-91eb-be51152a7b51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:48:25.108392Z",
     "start_time": "2023-09-17T20:48:24.680869Z"
    }
   },
   "outputs": [],
   "source": [
    "use_clip = type(model).__name__ == 'CLIP'\n",
    "save_prefix = 'CLIP_' if use_clip else ''\n",
    "load_ckpt = not use_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3a974b8-dd45-4c5e-a30d-ae7a6bb5d057",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:48:31.513374Z",
     "start_time": "2023-09-17T20:48:31.317160Z"
    }
   },
   "outputs": [],
   "source": [
    "load_ckpt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05dda52f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-17T20:48:43.767132Z",
     "start_time": "2023-09-17T20:48:43.632531Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "\n",
    "if use_clip:\n",
    "    encoder = model.encode_image\n",
    "    output_layer = None\n",
    "elif (not args.model.startswith('bert')): \n",
    "    encoder = torch.nn.Sequential(*(list(model.children())[:-1] + [torch.nn.Flatten()]))\n",
    "    output_layer = model.fc\n",
    "\n",
    "\n",
    "\n",
    "def process_batch(model, x, y = None, g = None, bert = True):\n",
    "    if bert:\n",
    "        input_ids = x[:, :, 0]\n",
    "        input_masks = x[:, :, 1]\n",
    "        segment_ids = x[:, :, 2]\n",
    "        outputs = model.bert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=input_masks,\n",
    "                token_type_ids=segment_ids,\n",
    "            )\n",
    "        pooled_output = outputs[1]\n",
    "        logits = model.classifier(pooled_output)\n",
    "        result = {'feature':pooled_output.detach().cpu().numpy(),\n",
    "                  'pred': np.argmax(logits.detach().cpu().numpy(), axis=1),\n",
    "                 }\n",
    "    else:\n",
    "        features = encoder(x)\n",
    "        result = {'feature':features.detach().cpu().numpy(),}        \n",
    "        if output_layer is not None:\n",
    "            logits = output_layer(features)\n",
    "            result['pred'] = np.argmax(logits.detach().cpu().numpy(), axis=1),\n",
    "    if y is not None: result['label'] = y.detach().cpu().numpy()\n",
    "    if g is not None: result['group'] = g.detach().cpu().numpy()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2156fc4e-d2b9-46cc-9150-6ad9e81f3910",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236e3f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-17T20:48:50.715504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Iter:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00d3bd6c2a15427ebddf795c91cf1b84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iter: ERM init 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/6443 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edebbff8274743e980d26461d6ece8fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "from itertools import product\n",
    "algos = ['ERM', ]\n",
    "# algos = ['ERM']\n",
    "model_selects = ['init']\n",
    "seeds = np.arange(10)\n",
    "for algo, model_select, seed in tqdm(list(product(algos,model_selects, seeds)),desc='Iter'):\n",
    "    print('Current iter:',algo, model_select, seed)\n",
    "    save_dir = f'/data/common/inv-feature/logs/{args.dataset}/{algo}/s{seed}/'\n",
    "    if load_ckpt:\n",
    "        model.load_state_dict(torch.load(save_dir + f'/{model_select}_model.pth',\n",
    "                     map_location='cpu').state_dict())\n",
    "\n",
    "    model.eval()\n",
    "    for split,loader in zip(['train', 'val', 'test'], [train_loader, val_loader, test_loader]):\n",
    "        results = []\n",
    "        fname = f'{split}_data.p'\n",
    "        fname = save_prefix + model_select + '_' + fname \n",
    "        if os.path.exists(save_dir + '/' + fname):\n",
    "            continue\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for batch_idx, batch in enumerate(tqdm(loader)):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                x = batch[0]\n",
    "                y = batch[1]\n",
    "                g = batch[2]\n",
    "                if args.model.startswith(\"bert\"):\n",
    "                    result = process_batch(model, x, y, g, bert=True)\n",
    "                else:\n",
    "                    result = process_batch(model, x, y, g, bert=False)\n",
    "                results.append(result)\n",
    "        parsed_data = {}\n",
    "        for key in results[0].keys():\n",
    "            parsed_data[key] = np.concatenate([result[key] for result in results])\n",
    "        \n",
    "        pickle.dump(parsed_data, open(save_dir + '/' + fname, 'wb'))\n",
    "\n",
    "        del results\n",
    "        del parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2adfca0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "isr",
   "language": "python",
   "display_name": "isr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
